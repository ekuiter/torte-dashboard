{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# pip install plotly pandas statsmodels kaleido scipy nbformat jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import json\n",
    "import pickle\n",
    "import scipy\n",
    "from statistics import mean, stdev\n",
    "from math import sqrt, log10\n",
    "from packaging.version import Version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_dataframe(stage, dtype={}, usecols=None, file=None, output_directory=\"output-linux\"):\n",
    "    if not file:\n",
    "        file = 'output'\n",
    "    df = pd.read_csv(f'{output_directory}/{stage}/{file}.csv', dtype=dtype, usecols=usecols)\n",
    "    if 'committer_date_unix' in df:\n",
    "        df['committer_date'] = df['committer_date_unix'].apply(lambda d: pd.to_datetime(d, unit='s'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for drawing plots\n",
    "\n",
    "def estimate_group(group):\n",
    "    print('\\\\hspace{2mm} ' + group + ' \\\\\\\\')\n",
    "\n",
    "def estimate_trend(fig, color=None, color_value=None, xs=[], key=lambda x: x.timestamp()):\n",
    "    results = px.get_trendline_results(fig)\n",
    "    if color is not None and color_value is not None:\n",
    "        idx = [i for i, r in enumerate(results.iloc) if r[color] == color_value]\n",
    "        if idx != []:\n",
    "            idx = idx[0]\n",
    "        else:\n",
    "            idx = 0\n",
    "    else:\n",
    "        idx = 0\n",
    "    intercept = results.iloc[idx]['px_fit_results'].params[0]\n",
    "    slope = results.iloc[idx]['px_fit_results'].params[1]\n",
    "    daily = slope * pd.to_timedelta(1, unit='D').total_seconds()\n",
    "    weekly = slope * pd.to_timedelta(7, unit='D').total_seconds()\n",
    "    monthly = slope * pd.to_timedelta(1, unit='D').total_seconds() * 30.437\n",
    "    yearly = slope * pd.to_timedelta(1, unit='D').total_seconds() * 365.25\n",
    "    return daily, weekly, monthly, yearly, [intercept + slope * key(x) for x in xs]\n",
    "\n",
    "def log10_y_axis(fig):\n",
    "    fig.update_yaxes(tickprefix = \"10<sup>\", ticksuffix = \"</sup>\")\n",
    "\n",
    "def percentage_y_axis(fig):\n",
    "    fig.layout.yaxis.tickformat = ',.0%'\n",
    "\n",
    "def format_percentage(value):\n",
    "    return str(round(value * 100, 2)) + '%'\n",
    "\n",
    "def committer_date_labels(dict={}):\n",
    "    return {'committer_date': 'Year<br><sup>First Release in Year</sup>'} | dict\n",
    "\n",
    "def revision_labels(dict={}):\n",
    "    return {'revision': 'Year'} | dict\n",
    "\n",
    "def style_legend(fig, position='topleft', xshift=0, yshift=0):\n",
    "    if position == 'topleft':\n",
    "        fig.update_layout(legend=dict(yanchor='top', y=0.98 + yshift, xanchor='left', x=0.01 + xshift))\n",
    "    elif position == 'topright':\n",
    "        fig.update_layout(legend=dict(yanchor='top', y=0.98 + yshift, xanchor='right', x=0.98 + xshift))\n",
    "    elif position == 'bottomright':\n",
    "        fig.update_layout(legend=dict(yanchor='bottom', y=0.01 + yshift, xanchor='right', x=0.98 + xshift))\n",
    "    elif position == 'bottomleft':\n",
    "        fig.update_layout(legend=dict(yanchor='bottom', y=0.01 + yshift, xanchor='left', x=0.01 + xshift))\n",
    "    else:\n",
    "        fig.update_layout(showlegend=False)\n",
    "\n",
    "def style_box(fig, legend_position='topleft', xshift=0, yshift=0):\n",
    "    fig.update_traces(fillcolor='rgba(0,0,0,0)')\n",
    "    fig.update_traces(line_width=1)\n",
    "    fig.update_traces(marker_size=2)\n",
    "    fig.update_layout(font_family=\"Linux Biolinum\")\n",
    "    style_legend(fig, legend_position, xshift, yshift)\n",
    "\n",
    "def style_scatter(fig, marker_size=4, legend_position='topleft', xshift=0, yshift=0):\n",
    "    if marker_size:\n",
    "        fig.update_traces(marker_size=marker_size)\n",
    "    style_legend(fig, legend_position, xshift, yshift)\n",
    "    fig.update_layout(font_family=\"Linux Biolinum\")\n",
    "\n",
    "def plot_failures(fig, df, x, y, y_value, align='bottom', xref='x', font_size=10, textangle=270):\n",
    "    group = df.groupby(x, dropna=False)\n",
    "    failures = (group[y].size() - group[y].count()).reset_index().rename(columns={y: f'{y}_failures'})\n",
    "    attempts = group[y].size().reset_index().rename(columns={y: f'{y}_attempts'})\n",
    "    failures = pd.merge(failures, attempts)\n",
    "    failures[f'{y}_text'] = failures[f'{y}_failures'].astype(str) + ' (' + (failures[f'{y}_failures'] / failures[f'{y}_attempts']).apply(lambda v: \"{0:.1f}%\".format(v * 100)) + ')'\n",
    "    for row in range(len(failures)):\n",
    "        text = failures.at[row, f'{y}_text']\n",
    "        text = \"\" if failures.at[row, f'{y}_failures'] == 0 else text\n",
    "        fig.add_annotation(\n",
    "            x=failures.at[row, x],\n",
    "            y=y_value,\n",
    "            text=text,\n",
    "            showarrow=False,\n",
    "            font_size=font_size,\n",
    "            textangle=textangle,\n",
    "            align='left' if align == 'bottom' else 'right',\n",
    "            yanchor='bottom' if align == 'bottom' else 'top',\n",
    "            yshift=5 if align == 'bottom' else -5,\n",
    "            font_color='gray',\n",
    "            xref=xref\n",
    "        )\n",
    "\n",
    "def cohens_d(d1, d2):\n",
    "    # uses pooled standard deviation\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    s1, s2 = np.var(d1, ddof=1), np.var(d2, ddof=1)\n",
    "    s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "    u1, u2 = np.mean(d1), np.mean(d2)\n",
    "    return (u1 - u2) / s\n",
    "\n",
    "def wilcoxon_test(df, column_a, column_b):\n",
    "    # if the same values are returned for many inputs, refer to https://stats.stackexchange.com/q/232927\n",
    "    a = df[column_a][~df[column_a].isna()]\n",
    "    b = df[column_b][~df[column_b].isna()]\n",
    "    d = a - b\n",
    "    results = scipy.stats.wilcoxon(d, method='approx')\n",
    "    p = results.pvalue\n",
    "    # adapted from https://stats.stackexchange.com/q/133077\n",
    "    r = np.abs(results.zstatistic / np.sqrt(len(d) * 2))\n",
    "    return p, r\n",
    "\n",
    "def style_p_values(fig, brackets, scale=0, _format=dict(interline=0.07, text_height=1.07, color='gray')):\n",
    "    # adapted from https://stackoverflow.com/q/67505252\n",
    "    for entry in brackets:\n",
    "        first_column, second_column, y, results = entry\n",
    "        y_range = [1.01+y*_format['interline'], 1.02+y*_format['interline']]\n",
    "        p, r = results\n",
    "        if p >= 0.05:\n",
    "            symbol = 'ns'\n",
    "        elif p >= 0.01: \n",
    "            symbol = '*'\n",
    "        elif p >= 0.001:\n",
    "            symbol = '**'\n",
    "        else:\n",
    "            symbol = '***'\n",
    "        first_column = first_column - scale\n",
    "        second_column = second_column + scale\n",
    "        fig.add_shape(type=\"line\",\n",
    "            xref=\"x\", yref=\"y domain\",\n",
    "            x0=first_column, y0=y_range[0],\n",
    "            x1=first_column, y1=y_range[1],\n",
    "            line=dict(color=_format['color'], width=2,)\n",
    "        )\n",
    "        fig.add_shape(type=\"line\",\n",
    "            xref=\"x\", yref=\"y domain\",\n",
    "            x0=first_column, y0=y_range[1], \n",
    "            x1=second_column, y1=y_range[1],\n",
    "            line=dict(color=_format['color'], width=2,)\n",
    "        )\n",
    "        fig.add_shape(type=\"line\",\n",
    "            xref=\"x\", yref=\"y domain\",\n",
    "            x0=second_column, y0=y_range[0], \n",
    "            x1=second_column, y1=y_range[1],\n",
    "            line=dict(color=_format['color'], width=2,)\n",
    "        )\n",
    "        fig.add_annotation(dict(font=dict(color=_format['color'],size=14),\n",
    "            x=(first_column + second_column)/2,\n",
    "            y=y_range[1]*_format['text_height'],\n",
    "            showarrow=False,\n",
    "            text=symbol + ' <sup>(' + str(round(r, 2)) + ')</sup>',\n",
    "            textangle=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"y domain\"\n",
    "        ))\n",
    "    return fig\n",
    "\n",
    "def bracket_for(i, j, xshift, y, results):\n",
    "    return [i + xshift, j + xshift, y, results]\n",
    "\n",
    "def filter_extractor(df, extractor):\n",
    "    return df[df['extractor'] == extractor]\n",
    "\n",
    "def annotate_value(fig, x, y, subplot, prefix, ax, ay, xanchor, df, fn=lambda prefix, y: prefix + ': ' + format(round(y), ',') if y > 0 else prefix):\n",
    "    if df.empty:\n",
    "        return\n",
    "    if isinstance(x, str):\n",
    "        x = df[x].iat[0]\n",
    "    if isinstance(y, str):\n",
    "        y = df[y].iat[0]\n",
    "    fig.add_annotation(\n",
    "        xref='x' + str(subplot),\n",
    "        yref='y' + str(subplot),\n",
    "        x=x,\n",
    "        y=y,\n",
    "        ax=ax,\n",
    "        ay=ay,\n",
    "        xanchor=xanchor,\n",
    "        text=fn(prefix, y)\n",
    "    )\n",
    "\n",
    "def show(fig, name=None, width=1000, height=500, margin=None):\n",
    "    # fig.update_layout(width=width, height=height)\n",
    "    if margin:\n",
    "        fig.update_layout(margin=margin)\n",
    "    else:\n",
    "        fig.update_layout(margin=dict(l=0, r=0, t=0, b=0))\n",
    "    \n",
    "    # if figures_directory and os.path.isdir(figures_directory) and name:\n",
    "        # fig.write_image(f'{figures_directory}/{name}.pdf')\n",
    "    # fig.write_html(f'{figures_directory}/{name}.html',config={\"responsive\":True})\n",
    "        \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latestData = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_arch(df):\n",
    "    grouped = df.groupby('architecture')\n",
    "    dfs = {arch: group for arch, group in grouped}\n",
    "    return dfs\n",
    "\n",
    "def read_dataframe(stage, dtype={}, usecols=None, file=None, arch=None, output_dir=\"output-linux\"):\n",
    "    if not file:\n",
    "        file = 'output'\n",
    "    df = pd.read_csv(f'{output_dir}/{stage}/{file}.csv', dtype=dtype, usecols=usecols)\n",
    "    if 'committer_date_unix' in df:\n",
    "        df['committer_date'] = df['committer_date_unix'].apply(lambda d: pd.to_datetime(d, unit='s'))\n",
    "    if arch != None:\n",
    "        return group_by_arch(df)[arch]\n",
    "    return df\n",
    "\n",
    "def read_dataframe_linux(stage, dtype={}, usecols=None, file=None, arch=None):\n",
    "    if not file:\n",
    "        file = 'output'\n",
    "    df = pd.read_csv(f'output-linux/{stage}/{file}.csv', dtype=dtype, usecols=usecols)\n",
    "    if 'committer_date_unix' in df:\n",
    "        df['committer_date'] = df['committer_date_unix'].apply(lambda d: pd.to_datetime(d, unit='s'))\n",
    "    if arch != None:\n",
    "        return group_by_arch(df)[arch]\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_values(df):\n",
    "    df.replace('kconfigreader', 'KConfigReader', inplace=True)\n",
    "    df.replace('kmax', 'KClause', inplace=True)\n",
    "\n",
    "def big_log10(str):\n",
    "    return log10(int(str)) if not pd.isna(str) and str != '' else pd.NA\n",
    "\n",
    "def process_model_count(df_solve):\n",
    "    df_solve['model-count'] = df_solve['model-count'].replace('1', '')\n",
    "    df_solve['model-count-log10'] = df_solve['model-count'].fillna('').apply(big_log10).replace(0, np.nan)\n",
    "    df_solve['year'] = df_solve['committer_date'].apply(lambda d: int(d.year))\n",
    "\n",
    "def peek_dataframe(df, column, message, type='str', filter=['revision', 'architecture', 'extractor']):\n",
    "    success = df[~df[column].str.contains('NA') if type == 'str' else ~df[column].isna()][filter]\n",
    "    failure = df[df[column].str.contains('NA') if type == 'str' else df[column].isna()][filter]\n",
    "    print(f'{message}: {len(success)} successes, {len(failure)} failures')\n",
    "    \n",
    "def jaccard(a, b):\n",
    "    return len(set.intersection(a, b)) / len(set.union(a, b))\n",
    "\n",
    "def add_features(descriptor, source, features, min=2):\n",
    "    descriptor[f'#{source}'] = len(features) if features is not None and len(features) >= min else np.nan\n",
    "\n",
    "def get_variables(variable_map):\n",
    "    variables = set(variable_map.values())\n",
    "    if len(variables) <= 1:\n",
    "        variables = set()\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Linux:\n",
    "    \n",
    "    def read_dataframe(self, stage, dtype={}, usecols=None, file=None, arch=None):\n",
    "        if not file:\n",
    "            file = 'output'\n",
    "        df = pd.read_csv(f'{self.output_directory}/{stage}/{file}.csv', dtype=dtype, usecols=usecols)\n",
    "        if 'committer_date_unix' in df:\n",
    "            df['committer_date'] = df['committer_date_unix'].apply(lambda d: pd.to_datetime(d, unit='s'))\n",
    "        if arch != None:\n",
    "            return group_by_arch(df)[arch]\n",
    "        return df\n",
    "    \n",
    "        \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.output_directory = \"output-linux\"\n",
    "        self.df_kconfig = self.read_dataframe('kconfig')\n",
    "        self.df_kconfig['year'] = self.df_kconfig['committer_date'].apply(lambda d: int(d.year))\n",
    "        self.df_architectures = self.read_dataframe(f'read-linux-architectures')\n",
    "        self.df_architectures = self.df_architectures.sort_values(by='committer_date')\n",
    "        self.df_architectures['year'] = self.df_architectures['committer_date'].apply(lambda d: int(d.year))\n",
    "        self.df_configs = self.read_dataframe(f'read-linux-configs')\n",
    "        self.df_configs = self.df_configs[~self.df_configs['kconfig-file'].str.contains('/um/')]\n",
    "        self.df_config_types = self.read_dataframe(f'read-linux-configs', file='output.types')\n",
    "        self.df_config_types = self.df_config_types[~self.df_config_types['kconfig-file'].str.contains('/um/')]\n",
    "        self.df_config_types = self.df_config_types.merge(self.df_architectures[['revision', 'committer_date']].drop_duplicates())\n",
    "        self.df_uvl = self.read_dataframe('model_to_uvl_featureide')\n",
    "        self.df_smt = self.read_dataframe('model_to_smt_z3')\n",
    "        self.df_dimacs = self.read_dataframe('dimacs')\n",
    "        self.df_backbone_dimacs = self.read_dataframe('backbone-dimacs')\n",
    "        self.df_solve = self.read_dataframe('solve_model-count', {'model-count': 'string'})\n",
    "        for df in [self.df_kconfig, self.df_uvl, self.df_smt, self.df_dimacs, self.df_backbone_dimacs, self.df_solve]:\n",
    "            df.replace('kconfigreader', 'KConfigReader', inplace=True)\n",
    "            df.replace('kmax', 'KClause', inplace=True)\n",
    "        # differentiate kinds of features\n",
    "        self.df_configs_configurable = self.df_configs.copy()\n",
    "        self.df_configs_configurable['configurable'] = False\n",
    "        with open(f'{self.output_directory}/linux-features.dat', 'rb') as f:\n",
    "            [self.features_by_kind_per_architecture, self.df_extractor_comparison, self.potential_misses_grep, self.potential_misses_kmax, self.df_configs_configurable] = pickle.load(f)\n",
    "\n",
    "        replace_values(self.features_by_kind_per_architecture)\n",
    "        self.df_features = pd.merge(self.df_architectures, self.features_by_kind_per_architecture, how='outer').sort_values(by='committer_date')\n",
    "        self.df_features = pd.merge(self.df_kconfig, self.df_features, how='outer').sort_values(by='committer_date')\n",
    "        self.df_total_features = self.df_features.groupby(['extractor', 'revision']).agg({'#total_features': 'min'}).reset_index()\n",
    "        self.df_total_features = pd.merge(self.df_kconfig[['committer_date', 'revision']].drop_duplicates(), self.df_total_features)\n",
    "\n",
    "    def total_features_latest(self):\n",
    "        kclause = int(self.df_total_features[self.df_total_features[\"extractor\"] == \"KClause\"].sort_values(\"committer_date\").tail(1)[\"#total_features\"])\n",
    "        kconf = int(self.df_total_features[self.df_total_features[\"extractor\"] == \"KConfigReader\"].sort_values(\"committer_date\").tail(1).iloc[0][\"#total_features\"])\n",
    "        return {\"currentValue\": f\"KClause: {kclause}\\nKConfigReader: {kconf}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linux_dfs = Linux()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39285/1313980941.py:48: FutureWarning:\n",
      "\n",
      "Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'currentValue': 'KClause: 20024\\nKConfigReader: 19869'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "linux_dfs.total_features_latest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_for(df, column, committer_date):\n",
    "    x = df.sort_values(by=[committer_date])\n",
    "    return x.tail(1)[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "/tmp/ipykernel_48656/1440899736.py:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  x = df[df['revision'].str.contains(\"\\w\\d+\\.0$\", regex=True)]\n"
     ]
    }
   ],
   "source": [
    "def by_revision(df):\n",
    "    x = df[df['revision'].str.contains(\"\\w\\d+\\.0$\", regex=True)]\n",
    "    if len(x) == 0:\n",
    "        x = df.sort_values(by=[\"revision\"])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_revision(df, revision):\n",
    "    x = df[df['revision'].str.contains(revision, regex=False)]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_arch(df, arch):\n",
    "    return df[df['architecture'] == arch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def write_object_to_file(obj, name):\n",
    "    with open(name, 'w') as fp:\n",
    "        json.dump(obj, fp)\n",
    "def read_json(path):\n",
    "    with open(path) as json_data:\n",
    "        return json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/tmp/ipykernel_48656/3637685965.py:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  before_last = df_arch[df_arch['revision'].str.contains(f\"\\w{major-1}\\.\\d$\", regex=True)]\n",
      "/tmp/ipykernel_48656/3637685965.py:16: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  before_last = df_arch[df_arch['revision'].str.contains(f\"\\w{major-1}\\.\\d$\", regex=True)]\n"
     ]
    }
   ],
   "source": [
    "def get_metrics_sloc_linux():\n",
    "    archs = list(linux_dfs.df_kconfig[\"architecture\"].unique())\n",
    "    archs.append(\"all\")\n",
    "    print(archs)\n",
    "    vals = dict()\n",
    "    for arch in archs:\n",
    "        df_arch = for_arch(linux_dfs.df_kconfig, arch)\n",
    "        if arch == \"all\":\n",
    "            df_arch = linux_dfs.df_kconfig\n",
    "        df_arch = by_revision(df_arch)\n",
    "        sloc = int(\n",
    "            latest_for(df_arch, \"source_lines_of_code\", \"committer_date_unix\").iloc[0]\n",
    "        )\n",
    "        last_rev = latest_for(df_arch, \"revision\", \"committer_date_unix\").iloc[0]\n",
    "        major = int(last_rev[1])\n",
    "        before_last = df_arch[df_arch['revision'].str.contains(f\"\\w{major-1}\\.\\d$\", regex=True)]\n",
    "        if len(before_last) == 0:\n",
    "            vals[f\"linux/{arch}\"] = {\n",
    "                \"source_lines_of_code\": {\n",
    "                    \"currentValue\": sloc,\n",
    "                    \"cmpLastRevision\": \"+100% (No Prior Revision)\",\n",
    "                }\n",
    "            }\n",
    "            continue\n",
    "        before_last = before_last[\"source_lines_of_code\"]\n",
    "        before_last = int(before_last.iloc[0])\n",
    "        value = round(100 * (sloc - before_last) / before_last, 2)\n",
    "        vals[f\"linux/{arch}\"] = {\n",
    "            \"source_lines_of_code\": {\n",
    "                \"currentValue\": f\"{sloc} loc\",\n",
    "                \"cmpLastRevision\": f\"{value:+.1f}%\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_features_linux():\n",
    "    archs = list(linux_dfs.df_kconfig[\"architecture\"].unique())\n",
    "    # archs.append(\"all\")\n",
    "    vals = dict()\n",
    "    for arch in archs:\n",
    "        df_arch = for_arch(linux_dfs.df_features, arch)\n",
    "        features = latest_for(df_arch, \"#features\", \"committer_date_unix\").iloc[0]\n",
    "        total_features = latest_for(linux_dfs.df_total_features, \"#total-features\", \"committer_date_unix\").iloc[0]\n",
    "        print(arch, total_features)\n",
    "        \n",
    "        vals[f\"linux/{arch}\"] = {\n",
    "            \"features\": {\n",
    "                \"currentValue\": f\"{int(features)} features\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_metrics(new):\n",
    "    old = read_json(\"vuetify-project/public/init.json\")\n",
    "    \n",
    "    for proj, metrics in new.items():\n",
    "        for metric, values in metrics.items():\n",
    "            # print(f\"{proj=}, {metric=}, {values=}\")\n",
    "            for name, value in values.items():\n",
    "                if proj not in old[\"projectData\"]:\n",
    "                    print(f\"{proj} not in old\")\n",
    "                    continue\n",
    "                old[\"projectData\"][proj][metric][name] = value\n",
    "    write_object_to_file(old, \"src/public/init.json\")\n",
    "    write_object_to_file(old, \"vuetify-project/public/init.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48656/1313980941.py:48: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  kclause = int(self.df_total_features[self.df_total_features[\"extractor\"] == \"KClause\"].sort_values(\"committer_date\").tail(1)[\"#total_features\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'currentValue': 'KClause: 20024\\nKConfigReader: 19869'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linux_dfs.total_features_latest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'committer_date_unix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48656/3209876260.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# new = get_metrics_sloc_linux()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# merge_metrics(new)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics_features_linux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# merge_metrics(new)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48656/3421362485.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0march\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marchs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdf_arch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfor_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinux_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatest_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_arch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"committer_date_unix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtotal_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatest_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinux_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_total_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#total-features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"committer_date_unix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         vals[f\"linux/{arch}\"] = {\n",
      "\u001b[0;32m/tmp/ipykernel_48656/3839514993.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, column, committer_date)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlatest_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommitter_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcommitter_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/torte/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7185\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7186\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7187\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7189\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7191\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/torte/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'committer_date_unix'"
     ]
    }
   ],
   "source": [
    "# new = get_metrics_sloc_linux()\n",
    "# merge_metrics(new)\n",
    "new = get_metrics_features_linux()\n",
    "# merge_metrics(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linux/alpha': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/arm': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/cris': {'source_lines_of_code': {'currentValue': '12882579 loc',\n",
       "   'cmpLastRevision': '+32.0%'}},\n",
       " 'linux/i386': {'source_lines_of_code': {'currentValue': 5518242,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/ia64': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/m68k': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/mips': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/mips64': {'source_lines_of_code': {'currentValue': 3740466,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/parisc': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/ppc': {'source_lines_of_code': {'currentValue': 6038869,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/ppc64': {'source_lines_of_code': {'currentValue': 4624754,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/s390': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/s390x': {'source_lines_of_code': {'currentValue': 3634003,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/sh': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/sparc': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/sparc64': {'source_lines_of_code': {'currentValue': 6468971,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/x86_64': {'source_lines_of_code': {'currentValue': 5518242,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/m68knommu': {'source_lines_of_code': {'currentValue': 9468369,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/v850': {'source_lines_of_code': {'currentValue': 6038869,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/h8300': {'source_lines_of_code': {'currentValue': 17848657,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/arm26': {'source_lines_of_code': {'currentValue': 5465319,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/m32r': {'source_lines_of_code': {'currentValue': '12882579 loc',\n",
       "   'cmpLastRevision': '+32.0%'}},\n",
       " 'linux/sh64': {'source_lines_of_code': {'currentValue': 5703916,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/frv': {'source_lines_of_code': {'currentValue': '12882579 loc',\n",
       "   'cmpLastRevision': '+32.0%'}},\n",
       " 'linux/xtensa': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/powerpc': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/avr32': {'source_lines_of_code': {'currentValue': '12882579 loc',\n",
       "   'cmpLastRevision': '+32.0%'}},\n",
       " 'linux/blackfin': {'source_lines_of_code': {'currentValue': '12882579 loc',\n",
       "   'cmpLastRevision': '+32.0%'}},\n",
       " 'linux/x86': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/mn10300': {'source_lines_of_code': {'currentValue': '12882579 loc',\n",
       "   'cmpLastRevision': '+32.0%'}},\n",
       " 'linux/microblaze': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/score': {'source_lines_of_code': {'currentValue': '12882579 loc',\n",
       "   'cmpLastRevision': '+32.0%'}},\n",
       " 'linux/tile': {'source_lines_of_code': {'currentValue': '12882579 loc',\n",
       "   'cmpLastRevision': '+32.0%'}},\n",
       " 'linux/unicore32': {'source_lines_of_code': {'currentValue': '17848657 loc',\n",
       "   'cmpLastRevision': '+38.5%'}},\n",
       " 'linux/openrisc': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/arc': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/arm64': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/c6x': {'source_lines_of_code': {'currentValue': '17848657 loc',\n",
       "   'cmpLastRevision': '+38.5%'}},\n",
       " 'linux/hexagon': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/metag': {'source_lines_of_code': {'currentValue': 12882579,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/nios2': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/riscv': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/nds32': {'source_lines_of_code': {'currentValue': 17848657,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/csky': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}},\n",
       " 'linux/loongarch': {'source_lines_of_code': {'currentValue': 24874347,\n",
       "   'cmpLastRevision': '+100% (No Prior Revision)'}},\n",
       " 'linux/all': {'source_lines_of_code': {'currentValue': '24874347 loc',\n",
       "   'cmpLastRevision': '+39.4%'}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_metrics(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"output-busybox\"\n",
    "df_kconfig = read_dataframe('kconfig', output_dir=output_directory)\n",
    "df_kconfig = df_kconfig[df_kconfig[\"system\"] ==\"busybox\"]\n",
    "def get_metrics_sloc_nonLinux(project):\n",
    "    vals = dict()\n",
    "    df_arch = by_revision(df_kconfig)\n",
    "    lastTwo = df_arch.sort_values(by=\"committer_date_unix\").tail(2)[\"revision\"]\n",
    "    print(lastTwo)\n",
    "    last_rev = lastTwo.iloc[1]\n",
    "    before_last_rev = lastTwo.iloc[0]\n",
    "    sloc = int(df_arch[df_arch[\"revision\"]==last_rev][\"source_lines_of_code\"].iloc[0])\n",
    "    before_last = int(df_arch[df_arch[\"revision\"]==before_last_rev][\"source_lines_of_code\"].iloc[0])\n",
    "    print(sloc, before_last)\n",
    "    value = round(100 * (sloc - before_last) / before_last, 2)\n",
    "    vals[project] = {\n",
    "        \"source_lines_of_code\": {\n",
    "            \"currentValue\": f\"{sloc} loc\",\n",
    "            \"cmpLastRevision\": f\"{value:+.1f}%\",\n",
    "        }\n",
    "    }\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85    1_35_0\n",
      "86    1_36_0\n",
      "Name: revision, dtype: object\n",
      "209492 205741\n"
     ]
    }
   ],
   "source": [
    "x = get_metrics_sloc_nonLinux(\"busybox\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merge_metrics(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torte",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
